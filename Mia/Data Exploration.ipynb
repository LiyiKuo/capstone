{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"sections\"></a></p>\n",
    "\n",
    "\n",
    "# Data Exploration\n",
    "</a><br>\n",
    "- <a href=\"#import\">Import Data</a><br>\n",
    "- <a href=\"#eda\">EDA Visualization</a><br>\n",
    "- <a href=\"#processing\">Data Processing</a><br>\n",
    "    - <a href=\"#domain\">Domain Knowledge Processing</a><br>\n",
    "    - <a href=\"#missing\">Missing Values</a><br>\n",
    "    - <a href=\"#transform\">Feature Transformation </a><br>\n",
    "    - <a href=\"#numeric\">Numeric Feature Processing </a><br>\n",
    "    - <a href=\"#categorical\">Categorical Feature Processing </a><br>\n",
    "    - <a href=\"#outliers\">Handling Outliers</a><br>\n",
    "</a><br>\n",
    "\n",
    "### Links:\n",
    "- **Comprehensive data exploration with Python** https://www.kaggle.com/wordsforthewise/eda-with-python\n",
    "- **Dataset 2007-2015 with more kernels** https://www.kaggle.com/wendykan/lending-club-loan-data\n",
    "- **Google Docs** https://docs.google.com/document/d/1vutUT82n14cegW-OhpKH4A2d2qsPeS14ZJvxSPeK-rI/edit?usp=sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 100\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as matplotlib\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LinearRegression \n",
    "# from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler \n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"import\"></a></p>\n",
    "\n",
    "## Import Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Importing data \n",
    "\n",
    "df_raw_accepted = pd.read_csv('accepted_2007_to_2018Q4.csv')\n",
    "df_raw_rejected = pd.read_csv('rejected_2007_to_2018Q4.csv')\n",
    "\n",
    "# df_raw_test = pd.read_csv('test.csv',index_col=0)\n",
    "# df_raw = pd.concat([df_raw, df_raw_test], sort = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_accepted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_rejected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2007 - 2016 Approval Rate\n",
    "1321847/11079386 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07558486045978391"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2007 - 2018 Approval Rate\n",
    "2260701/(2260701+27648741)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#may want to sample according ratio  \n",
    "#smote unbalance  \n",
    "\n",
    "df_raw_accepted.sample(3000).to_csv('sample_accepted.csv')\n",
    "df_raw_rejected.sample(3000).to_csv('sample_rejected.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted = pd.read_csv('sample_accepted.csv')\n",
    "sample_rejected = pd.read_csv('sample_rejected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_accepted.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_raw_accepted.columns)\n",
    "print(df_raw_rejected.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_raw_accepted.dtypes)\n",
    "print(df_raw_rejected.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "- **How are the loan amounts/funded amounts distributed?** \n",
    "-loan amounts is the listed amount of the loan applied for by the borrower. Funded amounts is the total amount committed to that loan at that point in time. 4 out of 2000 samples, funded amounts is less than loan amount, the others are the same. Funded amounts distribution is right skewed, mean $14,233\n",
    "- **Are there variations across different loan purposes, loan grades, etc?**\n",
    "- **Are loans with higher funded amounts harder to be paid-in-full?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sample_accepted['loan_amnt'],bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(sample_accepted['loan_amnt'],bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sample_accepted['funded_amnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted[sample_accepted['funded_amnt']!=sample_accepted['loan_amnt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotlist = ['term','grade','emp_length',\n",
    "            #'purpose',\n",
    "            'verification_status']\n",
    "\n",
    "for column in plotlist:\n",
    "    g = sns.FacetGrid(sample_accepted, col=column, hue=column, palette='Set1', size=10)\n",
    "    g.map(sns.distplot, 'funded_amnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"verification_status\", y=\"funded_amnt\", hue=\"grade\", kind=\"bar\", data=sample_accepted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"grade\", y=\"funded_amnt\", hue=\"term\", kind=\"bar\", data=sample_accepted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"grade\", y=\"funded_amnt\", hue=\"term\", kind=\"bar\", data=sample_accepted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"purpose\", y=\"funded_amnt\", kind=\"bar\", data=sample_accepted, size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.catplot(x=\"grade\", y=\"funded_amnt\", hue=\"home_ownership\", kind=\"bar\", data=sample_accepted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted.loan_status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_amount = sample_accepted[sample_accepted.funded_amnt>15000]\n",
    "small_amount = sample_accepted[sample_accepted.funded_amnt<15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_amount.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_amount[sample_accepted.loan_status == 'Fully Paid'].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "204/743"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_amount.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_amount[sample_accepted.loan_status == 'Fully Paid'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "379/2261"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"term\", hue=loan_status, data=large_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"loan_status\", y=\"funded_amnt\", kind=\"bar\", data=sample_accepted, size = 20) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "- For investors, the profitability of the loans is of their central \n",
    "concern. For a given loan, the profit-and-loss (in percentages) can be computed as\n",
    "the (total_payment - principal)/principal.\n",
    "- For those loans which are eventually 'Fully Paid', what are the average\n",
    "returns (or the distributions of returns) of different loan grades/terms?\n",
    "- For those loans wich are default or beyond, what are the average returns or return distributions?\n",
    "- What about all the loans which have been \n",
    "terminated ('fully paid', 'default', 'charged off')?\n",
    "- What about the loans which end up in **loan settlement negotiations**?\n",
    "- Any variation of patterns for different loan purposes?\n",
    "- What happens if the issuance years are included in your analysis?\n",
    "- Is there any pattern between loan duration vs return rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted['loan_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_paid = sample_return[sample_accepted['loan_status']=='Fully Paid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_paid.groupby('grade').aggregate({'return':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_paid.groupby('term').aggregate({'return':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_paid.groupby('sub_grade').aggregate({'return':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_return = sample_accepted.copy()\n",
    "sample_return['return'] = sample_return['total_pymnt']/sample_return['total_rec_prncp'] - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charged_off = sample_return[sample_accepted['loan_status']=='Charged Off']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charged_off.groupby('grade').aggregate({'return':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charged_off.groupby('term').aggregate({'return':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_return.groupby('loan_status').agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted[sample_accepted.loan_status == 'Charged Off']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted[sample_accepted.loan_status == 'Default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_accepted[df_raw_accepted.loan_status == 'Default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1615/1321847"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted = df_raw_accepted[df_raw_accepted.loan_status == 'Fully Paid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted['return'] = accepted['total_pymnt']/accepted['total_rec_prncp'] - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted['return'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(accepted['return'],bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_accepted = sample_accepted[sample_accepted.loan_status == 'Fully Paid']\n",
    "# sample_accepted['return'] = sample_accepted['total_pymnt']/sample_accepted['total_rec_prncp'] - 1 \n",
    "# sample_accepted['return'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sample_accepted['return'],bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <p><a name=\"eda\"></a></p>\n",
    "\n",
    "## EDA Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDistribution(df, primary_key, secondary_key):\n",
    "    cnt = df[primary_key].value_counts()\n",
    "    print('Count by primary key: ', primary_key)\n",
    "    print(cnt)\n",
    "    print('------------------------------------')\n",
    "    df_count1 = pd.DataFrame(df.groupby([primary_key, secondary_key]).count().iloc[:, 0])\n",
    "    print('Count by {} (primary key) and {} (secondary key)'.format(primary_key, secondary_key))\n",
    "    print(df_count1)\n",
    "    print('------------------------------------')\n",
    "    df_cnt_unstk_resetIdx = df_count1.unstack().reset_index()\n",
    "    for val in sorted(df[primary_key].unique()):\n",
    "        df_cnt_unstk_resetIdx[df_cnt_unstk_resetIdx[primary_key] == val].plot.bar(title = val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sample_accepted\n",
    "primary_key = 'purpose'\n",
    "secondary_key = 'grade'\n",
    "getDistribution(df, primary_key, secondary_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDistribution_numeric(df, primary_key, secondary_key):\n",
    "    cnt = df[primary_key].unique()\n",
    "    print('Count by primary key: ', primary_key)\n",
    "    print(cnt)\n",
    "    print('------------------------------------')\n",
    "    df_count1 = pd.DataFrame(df.groupby([primary_key, secondary_key]).count().iloc[:, 0])\n",
    "    print('Count by {} (primary key) and {} (secondary key)'.format(primary_key, secondary_key))\n",
    "    print(df_count1)\n",
    "    print('------------------------------------')   \n",
    "    for val in sorted(df[primary_key].unique()):\n",
    "        temp = df[df[primary_key] == val][[secondary_key]]\n",
    "        plt.figure(figsize = (10, 8))\n",
    "        _ = plt.hist(temp[secondary_key], bins = 20)\n",
    "        plt.title(val, fontdict=None, loc='center')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw_accepted\n",
    "primary_key = 'purpose'\n",
    "secondary_key = 'loan_amnt'\n",
    "getDistribution_numeric(df, primary_key, secondary_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <p><a name=\"processing\"></a></p>\n",
    "\n",
    "## Data Processing\n",
    "\n",
    "- <a href=\"#domain\">1.Domain Knowledge Processing</a><br>\n",
    "- <a href=\"#outliers\">2.Handling Outliers</a><br>\n",
    "- <a href=\"#missing\">3.Missing Values</a><br>\n",
    "- <a href=\"#transform\">4.Feature Transformation </a><br>\n",
    "- <a href=\"#numeric\">5.Numeric Feature Processing </a><br>\n",
    "\n",
    "- <a href=\"#DM\">6.Grouping Operations</a><br>\n",
    "- <a href=\"#miss\">7.Feature Split</a><br>\n",
    "- <a href=\"#grouping\">8.Scaling</a><br>\n",
    "- <a href=\"#grouping\">9.Extracting Date</a><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy so the raw data will not be affected \n",
    "df_processed = sample_accepted.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <p><a name=\"1-40\"></a></p>\n",
    " \n",
    "### Columns 1- 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = df_processed.iloc[:,:41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelavant columns \n",
    "drop_list = ['Unnamed: 0','id','member_id','funded_amnt','url','desc','title']\n",
    "\n",
    "drop_for_grade_list = ['funded_amnt_inv','int_rate','installment','issue_d','loan_status','pymnt_plan','out_prncp','out_prncp_inv']\n",
    "\n",
    "df_processed = df_processed.drop(drop_list, axis=1)\n",
    "df_processed = df_processed.drop(drop_for_grade_list, axis=1)\n",
    "\n",
    "# Convert categorical to numerical \n",
    "df_processed['term'] = df_processed['term'].apply(lambda x: int(x.split()[0]))\n",
    "df_processed['emp_length'] = df_processed['emp_length'].str.extract('(\\d+)') \n",
    "#10 means more than 10 years \n",
    "\n",
    "# Convert to Datetime\n",
    "df_processed['earliest_cr_line'] = pd.to_datetime(df_processed['earliest_cr_line'])\n",
    "\n",
    "# Missing Values \n",
    "\n",
    "df_processed.mths_since_last_record = df_processed.mths_since_last_record.fillna(0)\n",
    "df_processed.mths_since_last_delinq = df_processed.mths_since_last_delinq.fillna(0)\n",
    "\n",
    "df_processed.emp_title = df_processed.emp_title.fillna('None')\n",
    "df_processed.emp_length = df_processed.emp_length.fillna(0)\n",
    "\n",
    "df_processed.revol_util = df_processed.revol_util.fillna(0)\n",
    "\n",
    "df_processed.dti = df_processed.dti.fillna(df_processed.revol_bal / df_processed.annual_inc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_processed.emp_title.nunique()/len(df_processed.index)\n",
    "#df_raw_accepted.emp_title.nunique() / len(df_raw_accepted.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"missing\"></a></p>\n",
    "\n",
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total = df_processed.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df_processed.isnull().sum()/df_processed.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.columns[df_processed.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Value Processing \n",
    "df_processed.mths_since_last_record = df_processed.mths_since_last_record.fillna(0)\n",
    "df_processed.mths_since_last_delinq = df_processed.mths_since_last_delinq.fillna(0)\n",
    "\n",
    "df_processed.emp_title = df_processed.emp_title.fillna('None')\n",
    "df_processed.emp_length = df_processed.emp_length.fillna(0)\n",
    "df_processed.revol_util = df_processed.revol_util.fillna(0)\n",
    "df_processed.dti = df_processed.dti.fillna(df_processed.revol_bal / df_processed.annual_inc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.sum(df_processed.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"transform\"></a></p>\n",
    "\n",
    "### Feature Transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.SalePrice = np.log(df_clean.SalePrice)\n",
    "df_clean.GrLivArea = np.log(df_clean.GrLivArea)\n",
    "#df_clean.TotalBsmtSF = np.log(df_clean.TotalBsmtSF)\n",
    "# after processing missing value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram and normal probability plot\n",
    "sns.distplot(df_raw['SalePrice'], fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df_raw['SalePrice'], plot=plt)\n",
    "\n",
    "print(\"Skewness: %f\" % df_raw['SalePrice'].skew())\n",
    "print(\"Kurtosis: %f\" % df_raw['SalePrice'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram and normal probability plot\n",
    "sns.distplot(df_clean['SalePrice'], fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df_clean['SalePrice'], plot=plt)\n",
    "\n",
    "print(\"Skewness: %f\" % df_clean['SalePrice'].skew())\n",
    "print(\"Kurtosis: %f\" % df_clean['SalePrice'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram and normal probability plot\n",
    "sns.distplot(df_raw['GrLivArea'], fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df_raw['GrLivArea'], plot=plt)\n",
    "\n",
    "print(\"Skewness: %f\" % df_raw['GrLivArea'].skew())\n",
    "print(\"Kurtosis: %f\" % df_raw['GrLivArea'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram and normal probability plot\n",
    "sns.distplot(df_clean['GrLivArea'], fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df_clean['GrLivArea'], plot=plt)\n",
    "\n",
    "print(\"Skewness: %f\" % df_clean['GrLivArea'].skew())\n",
    "print(\"Kurtosis: %f\" % df_clean['GrLivArea'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram and normal probability plot\n",
    "sns.distplot(df_raw['TotalBsmtSF'], fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df_raw['TotalBsmtSF'], plot=plt)\n",
    "\n",
    "print(\"Skewness: %f\" % df_raw['TotalBsmtSF'].skew())\n",
    "print(\"Kurtosis: %f\" % df_raw['TotalBsmtSF'].kurt())\n",
    "\n",
    "# sns.distplot(df_clean['TotalBsmtSF'], fit=norm);\n",
    "# fig = plt.figure()\n",
    "# res = stats.probplot(df_clean['TotalBsmtSF'], plot=plt)\n",
    "\n",
    "# print(\"Skewness: %f\" % df_clean['TotalBsmtSF'].skew())\n",
    "# print(\"Kurtosis: %f\" % df_clean['TotalBsmtSF'].kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"numeric\"></a></p>\n",
    "\n",
    "### Numeric Feature Processing \n",
    "\n",
    "- scaler \n",
    "- normalization \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'YearBuilt'\n",
    "data = pd.concat([df_raw['SalePrice'], df_raw[var]], axis=1)\n",
    "f, ax = plt.subplots(figsize=(16, 8))\n",
    "fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n",
    "fig.axis(ymin=0, ymax=800000);\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    " \n",
    " ###  Categorical Features Processsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#box plot ordinal/saleprice\n",
    "ord_list = ['Foundation','MasVnrType','Exterior1st','RoofStyle',\n",
    "#             'RoofStyle', 'Neighborhood','LandSlope',\n",
    "#             'LotConfig','Utilities','LotShape','LandContour',\n",
    "#             'MSZoning','OverallQual','BsmtCond','Alley','BsmtExposure','BsmtFinType1','BsmtFinType2','BsmtQual','ExterCond','ExterQual','FireplaceQu','Functional','GarageCond','GarageQual','HeatingQC','KitchenQual','LandSlope','LotShape','PavedDrive','PoolQC',\n",
    "            'Street']\n",
    "for ordinal in ord_list:\n",
    "    data = pd.concat([df_raw['SalePrice'], df_raw[ordinal]], axis=1)\n",
    "    f, ax = plt.subplots(figsize=(8, 6))\n",
    "    fig = sns.boxplot(x=ordinal, y=\"SalePrice\", data=data)\n",
    "    fig.axis(ymin=0, ymax=800000);\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neighborhood\n",
    "df = df_clean[['SalePrice', 'GrLivArea', 'Neighborhood']]\n",
    "df['UnitPrice'] = df_clean.SalePrice / df_clean.GrLivArea\n",
    "df.groupby(['Neighborhood'])['UnitPrice'].agg({\"UnitPrice\":\"mean\"}).sort_values(['UnitPrice'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Encode some categorical features as ordered numbers when there is information in the order.\n",
    "df_clean = df_clean.replace({\"Alley\" : {\"None\":0,\"Grvl\" : 1, \"Pave\" : 2},\n",
    "                   \"Neighborhood\" : {\"SWISU\" : 1, \"IDOTRR\" : 2, \"OldTown\" : 3, \"BrDale\" : 4, \"Blueste\": 5,\n",
    "                   \"Edwards\" : 6, \"MeadowV\" : 7, \"BrkSide\" : 8, \"NWAmes\" : 9, \"NAmes\" : 10, \"NPkVill\" : 11, \"Sawyer\" : 12, \"Gilbert\": 13, \n",
    "                   \"SawyerW\" : 14, \"Crawfor\" : 15, \"ClearCr\" : 16, \"Mitchel\" : 17, \"NoRidge\": 18, \"Blmngtn\" : 19, \"CollgCr\" : 20, \"Timber\" : 21, \"Somerst\" : 22, \"Veenker\": 23, \"NridgHt\" : 24, \"StoneBr\": 25 },\n",
    "                   \"BsmtCond\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                   \"BsmtExposure\" : {\"None\" : 0,\"No\":1, \"Mn\" : 2, \"Av\": 3, \"Gd\" : 4},\n",
    "                   \"BsmtFinType1\" : {\"None\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4,\n",
    "                                     \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "                   \"BsmtFinType2\" : {\"None\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4,\n",
    "                                     \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "                   \"BsmtQual\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                   \"ExterCond\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "                   \"ExterQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "                   \"FireplaceQu\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                   \"Functional\" : {\"Sal\" : 1, \"Sev\" : 2, \"Maj2\" : 3, \"Maj1\" : 4, \"Mod\": 5,\n",
    "                                   \"Min2\" : 6, \"Min1\" : 7, \"Typ\" : 8},\n",
    "                   \"GarageCond\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                   \"GarageQual\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                   \"HeatingQC\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                   \"KitchenQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                   \"LandSlope\" : {\"Sev\" : 3, \"Mod\" : 2, \"Gtl\" : 1},\n",
    "                   \"LotShape\" : {\"IR3\" : 4, \"IR2\" : 3, \"IR1\" : 2, \"Reg\" : 1},\n",
    "                   \"PavedDrive\" : {\"N\" : 0, \"P\" : 1, \"Y\" : 2},\n",
    "                   \"PoolQC\" : {\"None\" : 0, \"Fa\" : 1, \"TA\" : 2, \"Gd\" : 3, \"Ex\" : 4},\n",
    "                   \"Street\" : {\"Grvl\" : 1, \"Pave\" : 2}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSSubClass processing - MSSubClass 20-90 contains only duplicate information with HouseStyle and YearBuilt\n",
    "# replace with 0 \n",
    "'''\n",
    "20\t1-STORY 1946 & NEWER ALL STYLES\n",
    "        30\t1-STORY 1945 & OLDER\n",
    "        40\t1-STORY W/FINISHED ATTIC ALL AGES\n",
    "        45\t1-1/2 STORY - UNFINISHED ALL AGES\n",
    "        50\t1-1/2 STORY FINISHED ALL AGES\n",
    "        60\t2-STORY 1946 & NEWER\n",
    "        70\t2-STORY 1945 & OLDER\n",
    "        75\t2-1/2 STORY ALL AGES\n",
    "        80\tSPLIT OR MULTI-LEVEL\n",
    "        85\tSPLIT FOYER\n",
    "        90\tDUPLEX - ALL STYLES AND AGES\n",
    "       120\t1-STORY PUD (Planned Unit Development) - 1946 & NEWER\n",
    "       150\t1-1/2 STORY PUD - ALL AGES\n",
    "       160\t2-STORY PUD - 1946 & NEWER\n",
    "       180\tPUD - MULTILEVEL - INCL SPLIT LEV/FOYER\n",
    "       190\t2 FAMILY CONVERSION - ALL STYLES AND AGES\n",
    "\n",
    "HouseStyle: Style of dwelling\n",
    "       \n",
    "       1Story One story\n",
    "       1.5Fin One and one-half story: 2nd level finished\n",
    "       1.5Unf One and one-half story: 2nd level unfinished\n",
    "       2Story Two story\n",
    "       2.5Fin Two and one-half story: 2nd level finished\n",
    "       2.5Unf Two and one-half story: 2nd level unfinished\n",
    "       SFoyer Split Foyer\n",
    "       SLvl   Split Level\n",
    "'''\n",
    "# df_clean['MSSubClass'] = df_clean['MSSubClass'].replace([20,30,40,45,50,60,70,75,80,85], 0)\n",
    "df_clean['MSSubClass'] = df_clean['MSSubClass'].replace(['20','30','40','45','50','60','70','75','80','85'], '0')\n",
    "\n",
    "# convert numerical to categorical \n",
    "# df_clean[['MSSubClass','OverallQual','OverallCond']] = df_clean[['MSSubClass','OverallQual','OverallCond']].astype(str)\n",
    "df_clean['MSSubClass'] = df_clean['MSSubClass'].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ordinal_list = ['OverallQual','OverallCond','ExterCond','BsmtQual','BsmtCond','HeatingQC','KitchenQual','Functional','FireplaceQu','GarageQual','PoolQC']\n",
    "\n",
    "# enc = OrdinalEncoder()\n",
    "# df_clean[ordinal_list] = enc.fit(df_clean[ordinal_list])\n",
    "\n",
    "# OverallQual\n",
    "# OverallCond\n",
    "# ExterCond\n",
    "# BsmtQual\n",
    "# BsmtCond\n",
    "# HeatingQC\n",
    "# KitchenQual\n",
    "# Functional\n",
    "# FireplaceQu\n",
    "# GarageQual\n",
    "# PoolQC\n",
    "\n",
    "\n",
    "## dummies \n",
    "df_clean = pd.get_dummies(df_clean, columns=df_clean.select_dtypes(include=['object']).columns, drop_first=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clean.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clean.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <p><a name=\"domain\"></a></p>\n",
    " \n",
    "### Domain Knowledge Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <p><a name=\"outliers\"></a></p>\n",
    " \n",
    " ### Handling Outliers \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"correlation\"></a></p>\n",
    "\n",
    "\n",
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation matrix\n",
    "corrmat = df_raw.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saleprice correlation matrix\n",
    "k = 10 #number of variables for heatmap\n",
    "cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
    "cm = np.corrcoef(df_raw[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatterplot\n",
    "sns.set()\n",
    "cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea','TotalBsmtSF', '1stFlrSF', 'FullBath', 'TotRmsAbvGrd', 'YearBuilt']\n",
    "sns.pairplot(df_raw[cols], size = 5)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatterplot\n",
    "sns.set()\n",
    "cols = [ 'OverallQual', 'GrLivArea', 'GarageArea','TotalBsmtSF', 'FullBath','SalePrice']\n",
    "sns.pairplot(df_raw[cols], size =5)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#histogram\n",
    "sns.distplot(df_raw['SalePrice']);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
