{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Idea 2:\n",
    "- A good loan (from the prospective of an investor) pays \n",
    "the interests and fractional principals on time and terminate at loan maturity.\n",
    "- An investor often lose money when a loan goes into default, settlement,\n",
    "or 'written off' (called **charged off** in this data set).\n",
    "- Build a supervised model to make **multi-label** prediction on 3 dimensions\n",
    "\"charged off + default\", \"settlement involved\", \"hardship\".\n",
    "- This can be used either by **Lending Club** itself or a third-party investing firm\n",
    "for loan-grade design or accurated portfolio selection.\n",
    "- Depending on the scope of your project, you may \n",
    "    - tackle a single label prediction.\n",
    "    - restrict to the pooled models.\n",
    "    - focus on the time seris models\n",
    "- This is a **multi-label** binary imbalance classification task.\n",
    "- If you train a **pooled** model, you have to deal with $2M+$ samples, often too\n",
    "large for a typical ML algorithm to handle.\n",
    "\n",
    "- Try several imbalance classification techniques and evaluate their performance.\n",
    "\n",
    "- Based on your business, discuss the negative impacts of type I (false\n",
    "positive), type II (false negative) errors in your prediction.\n",
    "\n",
    "- If you decide to train a time series model, make sure that you have some\n",
    "basic background on performing hyper-parameter tuning in the time series context.\n",
    "\n",
    "- **MUST**: A defaulted loan with a loan amount $\\$1000$ has a totally different \n",
    "impact to the final profit than a defaulted $\\$50000$ loan. \n",
    "   - Discuss whether the **classroom-taught** machine learning techniques \n",
    "    addresses these issues. How would you modify the classifier to take into account \n",
    "         - your business objectives.\n",
    "         - the profit and loss focus.\n",
    "\n",
    "- Can you use **NLP** technique to extract insights on the loan descriptions\n",
    "which helps your predictive task?\n",
    "</a><br>\n",
    "# Structure: \n",
    "- <a href=\"#preprocessing\">Preprocessing</a><br>\n",
    "    - <a href=\"#before\">Application Information before loan issued</a><br>\n",
    "    - <a href=\"#label\">Lables</a><br>\n",
    "    - <a href=\"#missing\">Missing Values</a><br>\n",
    "- <a href=\"#function\">Function</a><br>\n",
    "- <a href=\"#ml\">Machine Learning</a><br>\n",
    "    - Unsupervised Machine Learning  \n",
    "        - <a href=\"#kmeans\">K Means</a><br> \n",
    "\n",
    "    - Supervised Machine Learning      \n",
    "        - <a href=\"#decision\">Decision Tree</a><br>\n",
    "        - <a href=\"#rf\">Random Forest</a><br>\n",
    "        - <a href=\"#svm\">SVM</a><br>\n",
    "        - <a href=\"#xgboost\">XGBoost</a><br>\n",
    "        - <a href=\"#logistic\">Logistic Regression</a><br>\n",
    "        - <a href=\"#naive\">Naive Bayes Classifier</a><br>\n",
    "        - <a href=\"#neighbor\">Nearest Neighbor</a><br>\n",
    "- <a href=\"#imbalance\">Handling Imbalanced Data</a><br>\n",
    "    - <a href=\"#smote\">SMOTE</a><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 100\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_raw_accepted = pd.read_csv('accepted_2007_to_2018Q4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_accepted.sample(frac=0.001).to_csv('sample_accepted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_accepted = pd.read_csv('sample_accepted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted = sample_accepted.sample(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <p><a name=\"preprocessing\"></a></p>\n",
    " \n",
    " ## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = sample_accepted.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <p><a name=\"before\"></a></p>\n",
    " \n",
    " ### Application Information before loan is issued "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secondary Applicant\n",
    "\n",
    "joint_list = ['sec_app_fico_range_low','sec_app_fico_range_high',\n",
    "               'sec_app_earliest_cr_line','sec_app_inq_last_6mths',\n",
    "               'sec_app_mort_acc','sec_app_open_acc','sec_app_revol_util',\n",
    "               'sec_app_open_act_il','sec_app_num_rev_accts','sec_app_chargeoff_within_12_mths',\n",
    "               'sec_app_collections_12_mths_ex_med','sec_app_mths_since_last_major_derog',\n",
    "               'verification_status_joint','revol_bal_joint', \n",
    "               'dti_joint', 'application_type','annual_inc_joint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.loc[df_processed['application_type'] == 'Joint App',joint_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <p><a name=\"label\"></a></p>\n",
    " \n",
    " ### Lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Labels - \"charged off + default\", \"settlement involved\", \"hardship\" \n",
    "\n",
    "label_list = ['label_hardship','label_chargedoff_default','label_settlement', 'loan_status' ]\n",
    "chargedoff_default_list = ['Charged Off','Default', 'Does not meet the credit policy. Status:Charged Off']\n",
    "\n",
    "df_processed['label_hardship'] = df_processed['hardship_status'].apply(lambda x: 0 if x  is np.nan else 1)\n",
    "df_processed['label_chargedoff_default'] = df_processed['loan_status'].apply(lambda x: 1 if x in chargedoff_default_list else 0)\n",
    "df_processed['label_settlement'] = df_processed['settlement_status'].apply(lambda x: 0 if x  is np.nan else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardship Loans \n",
    "\n",
    "hardship_list = ['hardship_flag',\n",
    "     'hardship_type',\n",
    "     'hardship_reason',\n",
    "     'hardship_status',\n",
    "     'deferral_term',\n",
    "     'hardship_amount',\n",
    "     'hardship_start_date',\n",
    "     'hardship_end_date',\n",
    "     'payment_plan_start_date',\n",
    "     'hardship_length',\n",
    "     'hardship_dpd',\n",
    "     'hardship_loan_status',\n",
    "     'orig_projected_additional_accrued_interest',\n",
    "     'hardship_payoff_balance_amount',\n",
    "     'hardship_last_payment_amount',\n",
    "     'label_hardship'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.loan_status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed[hardship_list][df_processed['hardship_type'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settlement Loans \n",
    "\n",
    "settlement_list = ['debt_settlement_flag',\n",
    "     'debt_settlement_flag_date',\n",
    "     'settlement_status',\n",
    "     'settlement_date',\n",
    "     'settlement_amount',\n",
    "     'settlement_percentage',\n",
    "     'settlement_term']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed[settlement_list][df_processed['settlement_status'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = df_processed[label_list].copy()\n",
    "df_label['total'] = df_label['label_hardship'] + df_label['label_chargedoff_default'] + df_label['label_settlement']\n",
    "# df_label.loc[df_label['label_settlement'] == 1].sample(10)\n",
    "df_label.groupby(['total', 'label_hardship', 'label_settlement' , 'label_chargedoff_default']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label.loc[df_label['label_settlement'] == 1].groupby('loan_status').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label.loc[df_label['label_hardship'] == 1].groupby('loan_status').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig =go.Figure(go.Sunburst(\n",
    "    labels=[\"Charged Off\", \"Current\", \"Late\", \"Hardship\", \"Hardship\", \"Hardship\",\"Settlement\",\"Settlement\"],\n",
    "    parents=[\"Total\", \"Total\", \"Total\", \"Charged Off\", \"Current\", \"Late\", \"Charged Off\", \"Late\" ],\n",
    "    values=[980, 235, 743, 42, 5, 1, 3, 32, 1],\n",
    "))\n",
    "fig.update_layout(margin = dict(t=0, l=0, r=0, b=0))\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# https://plot.ly/python/sunburst-charts/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <p><a name=\"missing\"></a></p>\n",
    "    \n",
    "### Missing Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df_processed.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df_processed.isnull().sum()/df_processed.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelavant columns \n",
    "drop_list = ['Unnamed: 0','id','member_id','funded_amnt','url','desc','title']\n",
    "\n",
    "drop_for_grade_list = ['funded_amnt_inv','int_rate','installment','issue_d','loan_status','pymnt_plan','out_prncp','out_prncp_inv']\n",
    "\n",
    "df_processed = df_processed.drop(drop_list, axis=1)\n",
    "df_processed = df_processed.drop(drop_for_grade_list, axis=1)\n",
    "\n",
    "# Convert categorical to numerical \n",
    "df_processed['term'] = df_processed['term'].apply(lambda x: int(x.split()[0]))\n",
    "df_processed['emp_length'] = df_processed['emp_length'].str.extract('(\\d+)') \n",
    "#10 means more than 10 years \n",
    "\n",
    "# Convert to Datetime\n",
    "df_processed['earliest_cr_line'] = pd.to_datetime(df_processed['earliest_cr_line'])\n",
    "\n",
    "# Missing Values \n",
    "\n",
    "df_processed.mths_since_last_record = df_processed.mths_since_last_record.fillna(0)\n",
    "df_processed.mths_since_last_delinq = df_processed.mths_since_last_delinq.fillna(0)\n",
    "\n",
    "df_processed.emp_title = df_processed.emp_title.fillna('None')\n",
    "df_processed.emp_length = df_processed.emp_length.fillna(0)\n",
    "\n",
    "df_processed.revol_util = df_processed.revol_util.fillna(0)\n",
    "\n",
    "df_processed.dti = df_processed.dti.fillna(df_processed.revol_bal / df_processed.annual_inc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
